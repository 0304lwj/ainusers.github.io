<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<!--添加自适应标签-->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" shrink-to-fit=no">
	<title>甜先森</title>
	<!--title上面添加icon-->
	<link rel="shortcut icon" href="../../../../images/head/head.png"/>
</head>

    <!--引入外部样式-->
    <link href="../../../../product/bootstrap/css/bootstrap.css" rel="stylesheet">
    <link href="../../../../css/quanzhan/linux/slide.css" rel="stylesheet">
    <!--jqueryui-->
    <link href="../../../../product/jqueryui/jquery-ui.min.css" rel="stylesheet">
    <link href="http://jqueryui.com/resources/demos/style.css" rel="stylesheet">

<body>
    <div class="container-fluid">
        <div class="row">
            <div class="col-md-2">
                <!--left-->
                <ul id="nav">
                    <li>
                        <a href="#openstack">openstack</a>
                        <ul>
                            <li  class="current">
                                <a href="#jczs">基本知识</a>
                            </li>
                            <li>
                                <a href="#hjjc">环境检查</a>
                            </li>
                            <li>
                                <a href="#cygl">kvm常用管理</a>
                            </li>
                            <li>
                                <a href="#xnyh">kvm性能优化</a>
                            </li>
                            <li>
                                <a href="#cjjx">创建镜像</a>
                            </li>
                            <li>
                                <a href="#hjzb">环境准备</a>
                            </li>
                            <li>
                                <a href="#yhrz">keystone(认证)</a>
                            </li>
                            <li>
                                <a href="#jxfw">glance(镜像)</a>
                            </li>
                            <li>
                                <a href="#kzjd">Nova(控制节点)</a>
                            </li>
                            <li>
                                <a href="#jsjd">nova计算节点</a>
                            </li>
                            <li>
                                <a href="#wl">neutron(网络)</a>
                            </li>
                            <li>
                                <a href="#cjxnj">创建虚拟机</a>
                            </li>
                            <li>
                                <a href="#gl">dashboard管理</a>
                            </li>
                            <li>
                                <a href="#xnjcj">虚拟机的创建流程</a>
                            </li>
                            <li>
                                <a href="#yyp">cinder(云硬盘)</a>
                            </li>
                            <li>
                                <a href="#cjyyp">创建云硬盘</a>
                            </li>
                            <li>
                                <a href="#ztjg">openstack总结</a>
                            </li>
                        </ul>
                    </li>
                </ul>
            </div>
            <div class="col-md-10">
                <!--container-->
                <div id="container">
                    <div class="section" id="jczs">
                        <h2>基础知识</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
云计算openstack与kvm虚拟化
	云计算分类：私有云 公有云 混合云
	云计算是一种模式，虚拟化是一种技术
	云计算：通过网络来获取需要的资源可以弹性扩展按需付费
	虚拟化分为全虚拟化和半虚拟化
	单机虚拟化技术：esxi xenserver
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="hjjc">
                        <h2>环境检查</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
kvm环境检查
	kvm：linux中kenerl的一个模块
	qemu:虚拟机软件(模拟器)->模拟网卡声卡CPU等一系列环境
	如果网络不通？
	vi ifcfg-eth0
	vi /etc/resolv.conf
	kvm虚拟化创建(需要硬件支持)
	yum install -y qemu-kvm qemu-kvm-tools virt-manager libvirt virt-install
	查看当前虚拟机是否支持kvm虚拟化
	grep -E '(vmx|svm)' /proc/cpuinfo
	如果没有的话，可以vmware当前机器上右键processors中找到两个勾选项勾选即可
	disable accekeration和virtualize intel
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="cygl">
                        <h2>kvm常用管理</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
kvm常用管理(centos7)
	1.准备环境
		测试环境
		grep vmx /proc/cpuinfo	和 	grep svm /proc/cpuinfo
		1.创建镜像
		qemu-img create -f raw /opt/CentOS-7.1-x86_64.raw 10G
		查看有木有kvm	lsmod | grep kvm
		systemctl enable libvirtd.service
		systemctl start libvirtd.service
		systemctl status libvirtd.service
		2.挂载镜像
		查看环境：grep vmx /proc/cpuinfo
		挂载镜像：dd if=/dev/cdrom of=/opt/CentOS-7.1.iso
		装一台虚拟机
		virt-install --name CentOS-7.1-x86_64 --virt=type kvm --ram 1024
		--cdrom=/opt/CentOS-7.1.iso --disk path=/opt/CentOS-7.1-x86_64.raw
		--network network=default --graphics vnc,listen=0.0.0.0 --noautoconsole
		关闭防火墙：iptables -F
		查看selinux状态：getsebool
		查看iptables状态：iptables -vnL
		查看ip：ip ad li
		3.TightVNC客户端工具IP：10.0.0.111:5900（第一台，以后5901...）
		链接成功后在quiet后添加net.ifnames=0 biosdevname=0后点击instakll centos7
		1.standard partition标准分区
		/boot 1024M
		swap 2048M
		/ 剩余空间
		2.此时正在安装
	2.libvirt虚拟化管理工具(可以管理xen/kernel/vmware/virtual box)
		通过libvirt来实现对kvm的管理
		查看当前管理机器	virsh list
		1.安装完成之后root会关掉kvm虚拟机，然后使用virsh start centos-7.1-x86_64启动
		启动成功后查看ip：ifconfig不好使可以使用ip ad li
		centos7中使用ifconfig需要安装yum install net-tools
		2.编辑kvm参数
		virsh edit centos-7.1-x86_64
		<vcpu placement='auto' current="1">4<vcpu>
		重启生效
		virsh shutdown centos-7.1-x86_64
		virsh start centos-7.1-x86_64
	3.cpu的热添加(仅限于centos7且不支持热减少)
		查看cpu个数：cat /proc/cpuinfo
		或者
		cat /sys/devices/system/cpu/cpu0/online
		cat /sys/devices/system/cpu/cpu1/online
		或者
		cat /proc/interrupts
		添加cpu：修改cpu个数为2：virsh setvcpus centos-7.1-x86_64 2 --live
		如果没有成功添加需要将cpu1中的online置为1
		热添加理论上只能加不能减，总数不能超过最大数
		以上操作通过virsh调用libvirtAPI来控制kvm虚拟机，总述是修改配置文件
		配置文件位置如下：cat /etc/libvirt/qemu/centos-7.1-x86_64.xml
	4.内存的热添加(支持热减少)
		virsh edit centos-7.1-x86_64
		<memory>404876</memory>
		<currentmemory>1048576</currentmemory>
		重启生效
		virsh shutdown centos-7.1-x86_64
		virsh start centos-7.1-x86_64
		查看内存信息
		virsh qemu-monitor-command centos-7.1-x86_64 --hmp --cmd info ballon
		修改内存为600M(热添加和热减少直接修改数值即可)
		virsh qemu-monitor-command centos-7.1-x86_64 --hmp --cmd info ballon 600
		内存热膨胀和压缩，总数不能超过最大内存
	4.kvm的存储
		查看kvm的硬盘格式
		全镜像模式		稀疏模式
		raw			qcow2
	优点	直接分配好大小效率高	支持快照，压缩，镜像
		磁盘管理可以使用qemu-image进行管理
		比如查看信息：
		qemu-img info centos-7.1-x86_64.raw
	5.kvm桥接与nat
		依赖包：bridge-utils
		添加网桥：brctl addbr br0
		查看网桥：bridge show
		将eth0添加到新建的br0网桥中
		brctl addif br0 eth0
		给br0设置IP，首先需要将eth0中IP删除
		ip addr del dev eth0 10.0.0.111/24
		ifconfig br0 10..0.0111/24 up
		添加路由：route add default gw 10.0.0.2
		关闭防火墙：iptables -F
	6.删除虚拟机
		virsh undefine	删除后不会找回
		virsh destory	虚拟机直接关机
		virsh suspend centos-7.1-x86_64	中止虚拟机
		virsh resume   centos-7.1-x86_64	恢复虚拟机
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="xnyh">
                        <h2>kvm性能优化</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
kvm性能优化
    cpu：
    taskset：将某个进程绑定在某个cpu
    内存：
    影子页表(将虚拟机的虚拟内存/物理内存->映射到宿主机的虚拟内存/物理内存)[新技术EPT代替]
    KSM（内存合并[将连续的4k内存合并成为2M]）
    IO：
    默认virtio(较好)
1.linuxIO调度算法：(deadline性能较好[centos7默认])
    查看默认调度算法：dmesg | grep -i scheduler
    修改默认调度算法：echo cfq > /sys/block/sda/queue/scheduler
    查看调度算法列表：cat /sys/block/sda/queue/scheduler
    永久修改调度算法：elevator=noop
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="cjjx">
                        <h2>创建镜像</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
ovirt：创建虚拟机镜像
	开源邮箱zimbra
	存在镜像路径： cd /opt
	创建虚拟机镜像注意事项：
		1.IP配置中如果有uuid/mac需要删除或者注释掉
		2.selinux/iptables关掉
		3.分区的时候只分一个分区
		4.安装基础软件包：	net-tools lrzsz screen tree vim wget
	kvm管理平台
		openstack/cloudstack/oVirt
	安装ovirt
		前提配置：
		vi /etc/hosts
		10.0.0.111 old.boy.example.com
		yum localinstall http://resources.ovirt.org/pub/yum-repo/ovirt-release36.rpm
		yum install -y ovirt-engine
		yum install -y ovirt-engine-setup-plugin-allinone
		engine-setup
			遇到(firewalld)：输入firewalld
			acl权限：*(rw)
		直接访问客户端地址
			https://10.0.0.111或者https://10.0.0.111/ovirt-engine
			1.管理门户
			2.用户信息 admin/admin
			3.yum install -y ovirt-engine-setup-plugin-allinone
			4.然后新添加一台kvm机器
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="hjzb">
                        <h2>环境准备</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
openstack环境准备
		开源云计算管理平台
			计算，镜像，网络，存储，UI，认证，备份
		环境准备：
		1.centos7两台
			linux-node1.oldboyedu.com	192.168.56.11 eth0		控制节点
			linux-node1.oldboyedu.com	192.168.56.12 eth0		计算节点
		2.域名解析
			/etc/hosts
			192.168.56.11 linux-node1 linux-node1.oldboyedu.com
			192.168.56.12 linux-node2 linux-node2.oldboyedu.com
		3.安装vnc客户端


	openstack基础环境(centos7)
		centos7查看ip：ip ad li
		centos7查看路由：ip ro li
		1.配置主机名解析
			vi /etc/hosts
				192.168.56.11 linux-node1 linux-node1.oldboyedu.com
				192.168.56.12 linux-node2 linux-node2.oldboyedu.com
		2.时间同步
			安装
			yum install chrony
			配置
			vi /etc/chrony.conf
			# allow 192.168/16(将这条注释放开)
			启动
			systemctl enable chronyd.service
			systemctl start chronyd.service
			设置时区
			timedatectl set-timezone Asia/Shanghai
		3.安装样本源
			yum install centos-release-openstack-liberty
			yum install python-openstackclient
		4.安装mysql
			yum install -y mariadb mariadb-server MySQL-python
			移动配置文件位置
			cp /usr/share/mysql/my-medium.cnf   /etc/my.cnf
			修改配置
			vi /etc/my.cnf
			[mysqld]
			default-storage-engine = innodb
			innodb_file_per_table
			collation-server = utf8_general_ci
			init-connect = 'SET NAMS utf8'
			character-set-server = utf8
			启动数据库
			systemctl enable mariadb.service
			systemctl start mariadb.service
			初始化数据库
			mysql_secure_installation
			除设置密码外均输入Y
			登陆mysql
			mysql -uroot -p
			创建各种服务的数据库
			脚本如下
			keystone数据库
			msyql -u root -p -e "CREATE DATABASE keystone;"
			mysql -u root -p -e "GRANT ALL PRIVILEGES ON ketstone.* TO 'keystone'@'localhost' IDENTIFIED BY 'keystone';"
			mysql -u root -p -e "GRANT ALL PRICILEGES ON keystone.* TO 'KEYSTONE'@'%' IDENTIFIED BY 'keystone';"
			Glance数据库
			msyql -u root -p -e "CREATE DATABASE glance;"
			mysql -u root -p -e "GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'glance';"
			mysql -u root -p -e "GRANT ALL PRICILEGES ON glance.* TO 'KEYSTONE'@'%' IDENTIFIED BY 'glance';"
			Nova数据库
			msyql -u root -p -e "CREATE DATABASE nova;"
			mysql -u root -p -e "GRANT ALL PRIVILEGES ON nova.* TO 'glance'@'localhost' IDENTIFIED BY 'nova';"
			mysql -u root -p -e "GRANT ALL PRICILEGES ON nova.* TO 'KEYSTONE'@'%' IDENTIFIED BY 'nova';"
			Neutron数据库
			msyql -u root -p -e "CREATE DATABASE neutron;"
			mysql -u root -p -e "GRANT ALL PRIVILEGES ON neutron.* TO 'glance'@'localhost' IDENTIFIED BY 'neutron';"
			mysql -u root -p -e "GRANT ALL PRICILEGES ON neutron.* TO 'KEYSTONE'@'%' IDENTIFIED BY 'neutron';"
			Cinder数据库
			msyql -u root -p -e "CREATE DATABASE cinder;"
			mysql -u root -p -e "GRANT ALL PRIVILEGES ON cinder.* TO 'glance'@'localhost' IDENTIFIED BY 'cinder';"
			mysql -u root -p -e "GRANT ALL PRICILEGES ON cinder.* TO 'KEYSTONE'@'%' IDENTIFIED BY 'cinder';"
		5.安装rabbitmq-server
			安装
			yum install -y rabbitmq-server
			启动
			systemctl enable rabbitmq-server.service
			systemctl start rabbitmq-server.service
			安装netstat命令服务
			yum install net-tools
			查看启动端口
			netstat -natlp
			5672(rabbitmq端口号)
		6.rabbitmq客户端
			创建用户
			rabbitmqctl add_user openstack openstack
			授权
			rabbitmqctl set_permissions openstack ".*" ".*" ".*"
			启用zabbix管理插件
			rabbitmq-plugins enable rabbitmq management
			重启rabbitmq
			systemctl restart rabbitmq-server.service
			启动后查看15672端口
			netstat -natlp
			访问rabbitmq客户端
			192.168.56.11:15672
			guest/guest
			guest用户登陆后找到admin中将刚才创建的openstack用户的tags身份认证修改为administrator
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="yhrz">
                        <h2>keystone(用户认证)</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
keystone(用户认证)
        用户认证/服务目录
        1.关键字：
        user：用户		住宾馆的人
        tenant：租户 项目		宾馆
        token： 令牌		特别的钥匙
        role：角色		VIP等级用户
        service：服务		宾馆可提供各种服务
        endpoint：端点		具体的一种服务比如早餐等
    # keystone
        yum install -y openstack-keystone httpd mod_wsgi memcached python-memcached
        cd /opt
        yum install -y vim lrzsz
        修改配置文件
        vim /etc/keystone/keystone.conf
        生成随机码
        openssl rand -hex 10
            1.admin_token = 生成的随机码
            2.connection = mysql://keystone:keystone@192.168.56.11/keystone
            同步数据
            su -s /bin/sh -c "keystone-manage db_sync" keystone
            同步数据日志文件位置
            cd /var/log/keystone/keystone.log
            验证数据文件
            mysql -h 192.168.56.11 -u keystone -pkeystone
            use keystone
            show tables
            exit;
            3.memcache
            servers = 192.168.56.11:11211
            provider = uuid
            driver = memcache
            4.revoke
            driver = sql
            5.开启debug
            verbose = true
        启动memcache
            systemctl start memcached.service
        创建配置文件(keysstone两个端口)
            vim /etc/httpd/conf.d/wsgi-keystone.conf
            Listen 5000
            Listen 35357

            <VirtualHost *:5000>
                WSGIDaemonProcess keystone-public processes=5 threads=1
                user=keystone group=keystone display-name=%{GROUP}
                WSGIProcessGroup keystone-public
                WSGIScriptAlias / /usr/bin/keystone-wsgi-public
                WSGIApplicationGroup %{GLOBAL}
                WSGIPassAuthorization On
                <IfVersion >= 2.4>
                    ErrorLogFormat "%{cu}t %M"
                </IfVersion>
                ErrorLog /var/log/httpd/keystone-error.log
                CustomLog /var/log/httpd/keystone-access.log combined

                <Directory /usr/bin>
                    <IfVersion >= 2.4>
                        Require all granted
                    <IfVersion>
                    <IfVersion < 2.4>
                        Order allow,deny
                        Allow from all
                    </IfVersion>
                        </Directory>
            </VirtualHost>

            <VirtualHost *:35357>
                WSGIDaemonProcess keystone-public processes=5 threads=1
                user=keystone group=keystone display-name=%{GROUP}
                WSGIProcessGroup keystone-admin
                WSGIScriptAlias / /usr/bin/keystone-wsgi-admin
                WSGIApplicationGroup %{GLOBAL}
                WSGIPassAuthorization On
                <IfVersion >= 2.4>
                    ErrorLogFormat "%{cu}t %M"
                </IfVersion>
                ErrorLog /var/log/httpd/keystone-error.log
                CustomLog /var/log/httpd/keystone-access.log combined

                <Directory /usr/bin>
                    <IfVersion >= 2.4>
                        Require all granted
                    <IfVersion>
                    <IfVersion < 2.4>
                        Order allow,deny
                        Allow from all
                    </IfVersion>
                        </Directory>
            </VirtualHost>
        修改httpd配置文件
            vim /etc/httpd/conf/httpd.conf
            ServerName 192.168.56.11:80
        启动
            systemctl start memcached.service
            systemctl enable memcached
            systemctl start httpd
        验证启动服务
            netstat -ntlp | grep httpd
            启动端口有：
            5000/80/35357
            如果有问题，可以关闭一下selinux试一下
        配置环境变量
            export OS_TOKEN=生成的随机码
            export OS_URL=http://192.168.56.11:35357/v3
            export OS_INDETITY_API_VERSION=3
        创建admin项目
            openstack project create --domain default --description "Admin Project" admin
        创建admin用户
            openstack user create --domain default --password-prompt admin
            默认设置密码admin/admin
        创建admin角色
            openstack role create admin
        将admin用户加入admin项目并赋予admin角色
            openstack role add --project admin --user admin admin

        创建demo项目
            openstack project create --domain default --description "Demo Project" demo
        创建demo用户
            openstack user create --domain default --password=demo demo
            默认设置密码demo/demo
        创建user角色
            openstack role create user
        将demo用户加入demo项目并赋予user角色
            openstack role add --project demo --user demo user

        创建service服务协调各入门服务
            openstack project create --domain default --description "Service Project" service
    查看当前openstack用户信息
        openstack user list

        创建服务
            openstack service create --name keystone --description "OpenStack Identity" identity
        注册链接地址
            openstack endpoint create --region RegionOne identity public http://192.168.56.11:5000/v2.0
            openstack endpoint create --region RegionOne identity internal http://192.168.56.11:5000/v2.0
            openstack endpoint create --region RegionOne identity admin http://192.168.56.11:35357/v2.0
        设置完用户名和密码之后必须将环境变量去掉会导致冲突
            unset OS_TOKEN
            unset OS_URL
    链接keystone
        openstack --os-auth-url http://192.168.56.11:35357/v3 \
        --os-project-domain-id default --os-user-domain-id default \
        --os-project-name admin --os-username admin --os-auth-type password \
        token issue
        输入密码：admin
        如果获取返回值说明keystone环境成功
    配置keystone环境变量，方便执行命令
        vim admin-openrc.sh
        export OS_PROJRCT_DOMAIN_ID=default
        export OS_USER_DOMAIN_ID=default
        export OS_PROJECT_NAME=demo
        export OS_TENANT_NAME=demo
        export OS_USERNAME=demo
        export OS_PASSWORD=demo
        export OS_AUTH_URL=http://192.168.56.11:5000/v3
        export OS_IDENTITY_API_VERSION=3

        vim demo-openrc.sh
        export OS_PROJRCT_DOMAIN_ID=default
        export OS_USER_DOMAIN_ID=default
        export OS_PROJECT_NAME=demo
        export OS_TENANT_NAME=demo
        export OS_USERNAME=demo
        export OS_PASSWORD=demo
        export OS_AUTH_URL=http://192.168.56.11:5000/v3
        export OS_IDENTITY_API_VERSION=3
        chmod +x admin-openrc.sh demo-openrc.sh
    重新获取token
        openstack token issue
        配置后环境变量变得稍微简单些了
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="jxfw">
                        <h2>glance(镜像服务)</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
glance(镜像服务)
    主要分为三部分：api，registry(注册中心)，image store(镜像中心)
    安装
        yum intsall -y openstack-glance python-glance python-glance python-glanceclient
     修改配置文件
        vim /etc/glance/glance-spi.conf
        connection=mysql://glance:glance@192.168.56.11/glance
        vim /etc/glance/glance-registry.conf
        connection=mysql://glance:glance@192.168.56.11/glance
    查看修改配置
        grep -n "^connection" /etc/glance/glance-api.conf
    同步数据库
        su -s /bin/sh -c "glance-manage db_sync" glance
        检查一下
        mysql -h 192.168.56.11 -u glance -pglance
        如果glance库中有表说明没有问题
    创建glance用户
        openstack user create --domain default --password=glance glance
        如果不成功，必须先source一下admin的环境变量
        source admin-openrc.sh
        再重复执行一下就好
    将glance用户加入service项目并赋予admin角色
        openstack role add --project service --user glance admin
    修改配置文件
        1.api
            vim /etc/glance/glance-api.conf
            [keystone_authtoken]
            auth_uri = http://192.168.56.11:5000
            auth_url = http://192.168.56.11:35357
            auth_plugin = password
            project_domain_id = default
            user_domain_id = default
            project_name = service
            username = glance
            password = glance

            flavor=keystone	//使用keystone解析
        glance不适用消息队列
            notification_driver = noop
        镜像仓库配置
            default_store=file
            filesystem_store_datadir=/var/lib/glance/images/
        打开debug
            verbose=True
        2.registry
            vim /etc/glance/glance-registry.conf
            [keystone_authtoken]
            auth_uri = http://192.168.56.11:5000
            auth_url = http://192.168.56.11:35357
            auth_plugin = password
            project_domain_id = default
            user_domain_id = default
            project_name = service
            username = glance
            password = glance

            flavor=keystone	//使用keystone解析

        启动服务
            systemctl enable openstack-glance-api
            systemcrl enable openstack-glance-registry
            systemctl start openstack-glance-api
            systemcrl start openstack-glance-registry
        端口号查看
            netstat -ntalp
            registry端口号：9191
            api端口号：9292
    创建glance服务
        source admin-openrc.sh
        openstack service create --name glance --description "OpenStack Image service" image
    注册服务
        openstack endpoint create --region RegionOne
        image public http://192.168.56.11:9292
        openstack endpoint create --region RegionOne
        image internal http://192.168.56.11:9292
        openstack endpoint create --region RegionOne
        image admin http://192.168.56.11:9292
    在环境变量中添加glance
        echo "export OS_IMAGE_API_VERSION=2" \
        | tee -a admin-openrc.sh demo-openrc.sh
    测试glance是否安装成功
        glance image-list
    下载镜像
        wget http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img
    上传镜像
        glance image-create --name "cirros" \
        --file cirros-0.3.4-x86_64-disk.img \
        --disk-format qcow2 --container-format bare \
        --visibility public --progress
    查看镜像
        glance image-list
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="kzjd">
                        <h2>Nova（控制节点）</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
Nova（控制节点）
    1.nova api：外部访问nova的唯一途径
    2.nova scheduler：决策虚拟机创建在哪台主机(计算节点上)
            决策一个虚拟机应该调度在某物理节点，需要分两个步骤
            过滤：对现有机器进行存储空间等判断筛选出一批后进行算法匹配
            计算权值：实现匹配度的算法
    3.nova安装
        yum install openstack-nova-api openstack-nova-cert
        openstack-nova-conductor openstack-nova-console \
        openstack-nova-novncproxy openstack-nova-scheduler
        python-novaclient
    4.修改配置文件
        vim /etc/nova/nova.conf
        [database]
        connection=mysql://nova:nova@192.168.56.11/nova
    5.同步数据库
        su -s /bin/sh -c "nova-manage db sync" nova
        登陆数据库查看是否同步成功
        mysql -u nova -pnova
        use nova; -> show tables;
    6.修改nova中rabbitmq中配置
        vim /etc/nova/nova.conf
        rpc_backend=rabbit
        [oslo_messaging_rabbit]
        rabbit_host=192.168.56.11
        rabbit_port=5672
        rabbit_userid=openstack
        rabbit_password=openstack
    7.修改nova中keystone中配置之前需要创建用户
        1.修改配置之前首先要创建用户
        openstack user create --domain default --password=nova nova
        2.将nova用户加入service项目并赋予admin角色
        openstack role add --project service --user nova admin
    8.修改nova中keystone中配置
        vim /etc/nova/nova.conf
        [keystone_authtoken]
        粘贴在下面
        auth_uri = http://192.168.56.11:5000
        auth_url = http://192.168.56.11:35357
        auth_plugin = password
        project_domain_id = default
        user_domain_id = default
        project_name = service
        username = nova
        password = nova
        [default]
        auth_strategy=keystone
        network_api_class=nova.network.neutronv2.api.API
        security_group_api=neutron
        linuxnet_interface_driver=nova.network.linux_net.NeutronLinuxBridgeInterfaceDriver
        firewall_driver=nova.virt.firewall.NoopFirewallDriver
        my_ip=192.168.56.11
        vncserver_listen=$my_ip
        vncserver_proxyclient_address=$my_ip
        [glance]
        host=$my_ip
        lock_path=/var/lib/nova/tmp
        enabled_apis=osapi_compute,metadata
    9.启动服务
        systemctl enable openstack-nova-api.service \
        openstack-nova-cert.service openstack-nova-consoleauth.service \
        openstack-nova-scheduler.service openstack-nova-conductor.service \
        openstack-nova-novncproxy.service

        systemctl start openstack-nova-api.service \
        openstack-nova-cert.service openstack-nova-consoleauth.service \
        openstack-nova-scheduler.service openstack-nova-conductor.service \
        openstack-nova-novncproxy.service
    10.在keystone上面做注册
        source admin-openrc.sh
        openstack service create --name nova --description "OpenStackCompute" compute
        openstack endpoint create --region RegionOne compute public http://192.168.56.11:8774/v2/%\(tenant_id\)s
        openstack endpoint create --region RegionOne compute internal http://192.168.56.11:8774/v2/5\(tenant_id\)s
        openstack endpoint create --region RegionOne compute admin http://192.168.56.11:8774/v2/%\(tenant_id\)s
        测试是否正常
        openstack host list
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="jsjd">
                        <h2>nova计算节点</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
nova计算节点
    nova computer一般运行在计算节点上面，通过发消息控制vm的生命周期
    nova computer通过libvirt管理kvm，通过xenapi管理xen
    1.新节点node2环境
        关闭selinux
        关闭iptables
        添加host解析：vim /etc/hosts
        测试host解析：ping linux-node2	ping linux-node2.oldboyedu.com
    2.搭建环境
        scp /etc/nova/nova.conf 192.168.56.12:/etc/nova/
        修改配置文件
        vim /etc/nova/nova.conf
        my_ip=192.168.56.12
        vncserver_listen=0.0.0.0
        novncproxy_base_url=http://192.168.56.11:6080/vnc_auto.html
        vnc_enabled=true
        vnc_keymap=en-us
        [glance]
        host=192.168.56.11
        测试是否支持kvm
        grep -E ‘（vmx|svm）’ /proc/cpuinfo
        如果有显示信息，确认支持
        virt_type=kvm(如果没有配置成qemu也可以)
        vncserver_proxyclient_address=192.168.56.12
    2.安装时间服务器
        yum install -y chrony
        修改配置文件
        vim /etc/chrony.conf
        只保留一行
        server 192.168.56.11 iburst
    3.设置时区
        timedatectl set-timezone Asia/Shanghai
    4.设置开机自动启动和启动
        systemctl enable chronyd.service
        systemctl start chronyd.service

        systemctl enable libvirtd openstack-nova-compute
        systemctl start     libvirtd openstack-nova-compute
        验证状态
        systemctl status libvirtd
        systemctl status openstack-nova-compute
    5.验证nova计算节点是否正常
        source admin-openrc.sh
        openstack host list
    6.测试一下glance
        nova image-list
    7.测试一下keystone
        nova endpoints
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="wl">
                        <h2>neutron(网络)</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
neutron(网络)
    node1(控制节点)
    1.在keystone上面注册neutron服务
        source admin-openrc.sh

        openstack service create --name neutron --description
        "OpenStack Networking" network
        openstack endpoint create --region ReginOne network public
        http://192.168.56.11:9696
        openstack endpoint create --region RegionOne network internal
        http://192.168.56.11:9696
        openstack endpoint create --region RegionOne network admin
        http://192.168.56.11:9696
    2.拷贝neutron配置文件
        cp /opt/config/neutron.conf /etc/neutron/neutron.conf
    3.修改配置文件
        vim /opt/config/neutron.conf
        connection = mysql://neutron:neutron@192.168.56.11:3306/neutron
        [keystone_authtoken]
        auth_uri = http://192.168.56.11:5000
        auth_url = http://192.168.56.11:35357
        auth_plugin = password
        project_domain_id = default
        user_domain_id = default
        project_name = service
        username = neutron
        password = neutron
        rabbit_host = 192.168.56.11
        core_plugin = ml2
        service_plugins = router
        notify_nova_on_port_status_changes = True
        notify_nova_on_port_data_changes = True
        nova_url = http://192.168.56.11:8774/v2
        [nova]
        auth_url = http://192.168.56.11:35357
        auth_plugin = password
        project_domain_id = default
        user_domain_id = default
        region_name = RegionOne
        project_name = service
        username = nova
        password = nova
        lock_path = $state_path/lock
    4.移动文件
        cp /opt/config/ml2_conf.ini /etc/neutron/plugins/ml2/
        vim /etc/neutron/plugins/ml2//ml2_conf.ini
        type_drivers = flat,vlan,gre,vxlan,geneve
        tenant_network_types=vlan,gre,vxlan,geneve
        mechanism_drivers=openvswitch,linuxbridge
        extension_drivers = port_security
        flat_networks = physnetl
    5.移动文件
        cp /opt/config/linuxbridge_agent.ini /etc/neutron/plugins/ml2
        vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini
        vim /etc/neutron/dhcp_agent.ini
        将interface_driver注释打开
        将dhcp_driver注释打开
        将enable_isolated_metadata=true
        vim /etc/neutron/metadata_agent.ini
    6.修改nova配置
        vim /etc/nova/nova..conf
        [neutron]
        url=http://192.168.56.11:9696
        auth_url = http://192.168.57.11:35357
        auth_plugin = password
        project_domain_id=default
        user_domain_id=default
        region_name=RegionOne
        projrct_name=service
        username=neutron
        password=neutron
        service_metadata_proxy=true
        metadata_proxy_shared_secret=neutron
    7.创建软连接
        ln -s /etc/neutron/plugins/ml2/ml2_conf.ini  /etc/neutron/plugin.ini
    8.创建keystone的neutron用户
        source admin-openrc.sh
        openstack user create --domain default --password=neutron neutron
    9.添加用户
        openstack role add --project service --user neutron admin
    10.执行
        su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf \
        --config-file /etc/neutron/plugins/ml2/ml2_config.ini upgrade head" neutron
    11.重启服务
        1.systemctl restart openstack-nova-api
        2.systemctl enable neutron-server.service \
        neutron-linuxbridge-agent.service neutron-dhcp-agent.service \
        neutron-metadata-agent.service
        systemctl start neutron-server.service \
        neutron-linuxbridge-agent.service neutron-dhcp-agent.service \
        neutron-metadata-agent.service
    12.测试
        neutron agent-list

    node2(计算节点)
    1.yum install -y openstack-meutron openstack-neutron-linuxbridge
    ebtables ipset
    2.从node1上面拷贝文件到noode2
        scp /etc/neutron/neutron.conf 192.168.56.12:/etc/neutron/
        scp /etc/neutron/plugins/ml2/linuxbridge_agent.ini 192.168.56.12:/etc/neutron/plugins/ml2/
        scp /etc/neutron/plugins/ml2/ml2_conf.ini 192.168.56.12:/etc/neutron/plugins/ml2/
    3.修改nova配置
        vim /etc/nova/nova.conf
        url = http://192.168.56.11:9696
        auth_url = http://192.168.56.11:35357
        auth_plugin = password
        project_domain_id = default
        user_domain_id = default
        region_name = RegionOne
        peoject_name = service
        username = neutron
        password = neutron
    4.重启服务
        systemctl restart openstack-nova-compute
    5.添加软连接
        ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
    6.启动服务
        systemctl enable neutron-linuxbridge-agent.service
        systemctl start neutron-linuxbridge-agent.service
    7.在node1控制节点上面测试(应该有四个agent)
        neutron agent-list
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="cjxnj">
                        <h2>创建虚拟机</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
创建虚拟机
    node1
    1.source admin-openrc.sh
    2.neutron net-create flat --shared --peovider:physical_network physnet1 --provider:network_type flat
    (其中的physnet1是从node2节点上面vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini中查看的)
    3.创建子网络
        neutron subnet-create flat 192.168.56.1/24 --name flat-subnet --allocation-pool start=192.168.56.100,end=192.168.56.200 \
        --dns-nameserver 192.168.56.2 --gateway 192.168.56.2
    4.查看创建网络
        neutron subnet-list
    5.将node2上面的shcp关闭
        虚拟网络编辑器->不勾选(使用dhcp)
    6.使用demo用户创建虚拟机
        source demo-openrc.sh
    7.生成公钥
        ssh-keygen -q -N ""
    8.添加公钥
        nova keypair-add --pub-key .ssh/id_rsa.pub mykey
    9.查看是否添加成功
        nova keypair-list
    10.安全组
        nova secgroup-add-rule default icmp -1 -1 0.0.0.0/0
        nova secgroup-add-rule default tcp 22 22 0.0.0.0/0
    11.查看虚拟机类型
        nova flavor-list
    12.查看镜像类型
        nova image-list
    13.查看网络类型
        neutron net-list
    14.创建虚拟机(nicnet-id必须使用id)
        nova boot --flavor m1.tiny --image cirros --nicnet-id=b997c94b-64a9-4c64-96ed-7f972f3d329c --security-group default \
        --key-name mykey hello-instance
    15.查看虚拟机是否创建成功
        nova list
    16.测试一下
        ping 192.168.1.101
        ssh cirros@192.168.56.101
    17.获取url登陆web客户端
        nova get-vnc-console hello-instance novnc
    18.获取到url之后，打开浏览器访问
        默认的用户登录信息都会在上面显示
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="gl">
                        <h2>dashboard(管理openstack)</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
dashboard(管理openstack)
    node1
    1.安装
    yum install -y openstack-dashboard
    2.修改配置文件
    vi /etc/openstack-dashboard/local_settings
    OPENSTACK_HOST="192.168.56.11"
    OPENSTACK_KEYSTONE_DEFAULT_ROLE="user"
    ALLOWED_HOSTS=['*',]
    把CACHES注释打开并且修改'LOCATION':'192.168.56.11:11211'
    TIME_ZONE="Asia/Shanghai"
    3.重启httpd
    systemctl restart httpd
    4.访问客户端
    192.168.56.11/dashboard
    demo/demo
    admin/admin
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="xnjcj">
                        <h2>虚拟机的创建流程</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
虚拟机的创建流程
    dashboard(登陆openstack客户端)->keystone(进行验证)->nova(开始调度创建)
    ->glance(给nova一个镜像id)->keystone(查看nova中的token是否有效)
    ->neutron(给nova一个网卡)->keystone(查看nova中的token是否有效)
    -cinder(给nova一个云硬盘)->keystone(查看nova中的token是否有效)
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="yyp">
                        <h2>cinder(云硬盘)</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
cinder(云硬盘)
    1.可以任意挂载，缺点是网络IO
    node1(控制节点)
    1.安装
        yum install -y openstack-cinder python-cinderclient
    2.查看是否有cinder库
        mysql -u root -p
    3.创建数据库
        grant all on cinder.* to cinder@localhost identified by 'cinder';
        grant all on cinder.* to cinder@'%' identified by 'cinder';
    4.验证创建
        show databases;
    5.修改配置文件
        vi /etc/cinder/cinder.conf
        [database]
        connection = mysql://cinder:cinder@192.168.56.11/cinder
    6.同步数据库
        su -s /bin/sh -c "cinder-manage db sync" cinder
    7.测试同步cinder表
        mysql -h 192.168.56.11 -u cinder -pcinder -e "use cinder;show tables"
    8.创建cinder用户
        source admin-openrc.sh
        openstack user create --domain default --password-prompt cinder
    9.加入service项目赋予admin权限
        openstack role add --project service --user cinder admin
    10.修改cinder.conf配置文件
        vi /etc/cinder/cinder.conf
        auth_strategy=keystone
        [keystone_authtoken]
        auth_uri = http://192.168.56.11:5000
        auth_url = http://192.168.56.11:35357
        auth_plugin = password
        project_domain_id = default
        user_domain_id = default
        project_name = service
        username = cinder
        password = cinder

        rpc_backend = rabbit
        rabbit_host=192.168.56.11
        rabbit_port = 5672
        rabbit_userid = openstack
        rabbit_password = openstack

        glance_host = 192.168.56.11
        lock_path = /var/lib/cinder/tmp
    11.配置nova
        vi /etc/nova/nova.conf
        [cinder]
        os_region_name = RegionOne
    12.启动
        systemctl restart openstack-nova-api.service
        systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service
        systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service
    13.创建服务
        openstack service create --name cinder \
        --description "OpenStack Block Storage" volume
        openstack service create --name cinderv2 \
        --description "OpenStack Block Storage" volumev2
    14.创建目标
        openstack endpoint create --region RegionOne \
        volume public http://192.168.56.11:8776/v1/%\{tenant_id\}s

        openstack endpoint create --region RegionOne \
        volume internal http://192.168.56.11:8776/v1/%\{tenant_id\}s

        openstack endpoint create --region RegionOne \
        volume admin http://192.168.56.11:8776/v1/%\{tenant_id\}s

        openstack endpoint create --region RegionOne \
        volume public http://192.168.56.11:8776/v2/%\{tenant_id\}s

        openstack endpoint create --region RegionOne \
        volume internal http://192.168.56.11:8776/v2/%\{tenant_id\}s

        openstack endpoint create --region RegionOne \
        volume admin http://192.168.56.11:8776/v2/%\{tenant_id\}s
    15.把计算机点node2关机添加一块硬盘
        步骤默认即可
    16.创建lvm
        pvcreate /dev/sdb
        vgcreate cinder-volumes /dev/sdb
    17.修改配置文件
        vim /etc/lvm/lvm.conf
        [devices]
        filter = [ "a/sdb/","r/.*/" ]
    18安装管理scsi(硬盘的工具)
        yum install -y openstack-cinder targetcli python-oslo-policy
    19.传递配置文件
        scp /etc/cinder/cinder.conf 192.168.56.12:/etc/cinder/cinder.conf
    20.修改配置文件
        vi /etc/cinder/cinder.conf
        在最下面创建，复制如下内容
        [lvm]
        volume_driver = cinder.volume.drivers.lvm.LVMVolemeDriver
        volume_group = cinder-volumes
        iscsi_protocol = iscsi
        iscsi_helper = lioadm

        enabled_backends = lvm
    21.启动cinder云硬盘
        systemctl enable openstack-cinder-volume.service target.service
        systemctl start openstack-cinder-volume.service target.service
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="cjyyp">
                        <h2>创建云硬盘</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
创建云硬盘
    cobbler同步阿里仓库
        cobbler repo add -name=openstack-liberty
        --mirror=http://mirrors.aliyun.com/centos/7.1.1503/cloud/x86_64/openstack-liberty/
        --arch=x86_64
        cobbler reposync
    node1
    1.验证节点
        source admin-openrc.sh
        cinder service-list
        如果出现down的情况，可能原因是时间不同步
        解决：在两个节点上面安装ntp时间同步
        然后执行ntpdate ntp.aliyun.com
        node2
        重启openstack-cinder
        systemctl restart openstack-cinder-volume.service
        两个均位up的状态
    2.创建云硬盘
        1.登陆dashboard
        demo/demo
        2.登陆后会在左侧菜单中看到云硬盘
        3.点击创建云硬盘
        demo/demo/1G即可，其他默认
        4.挂载云硬盘到虚拟主机上面啊
        云硬盘list右侧编辑卷->管理已挂载的云硬盘
        5.如果实例关闭，得启动实例
        6.点击云主机控制台不能正常启动，请参照7-8
        7.ifconfig -a(查看网桥IP是否正常，如果网桥没有IP,请操作如下步骤)
        8.systemctl restart neutron-linuxbridge-agent
           在dashboard页面中硬重启实例
    3.挂载云硬盘
        1.查看硬盘sudo fdisk -l
        2.sudo fdisk /dev/vdb
        3.n,p,回车,回车,w
        4.格式化文件系统
           sudo mkfs.ext4 /dev/vdb1
        5.创建目录并挂载
           sudo mkdir /data
           sudo mount /dev/vdb1 /data
        6.sudo mount
        7.cd /data
        8.现在就可以创建文件了，不过需要加上sudo
    4.卸载云硬盘
        1.sudo umount /data
        2.sudo mount
        3.在dashboard页面找到云硬盘中编辑卷->管理已挂载云硬盘->卸载云硬盘
        4.现在这块云硬盘就可以挂载到其他主机上面去了
                            </ol>
                        </pre>
                    </div>
                    <div class="section" id="ztjg">
                        <h2>openstack整体架构</h2>
                        <pre class="prettyprint linenums">
                            <ol class="linenums">
openstack整体架构
    keystone：权限控制
    neutron：网络资源
    cinder：云硬盘
    glance：镜像仓库
    nova：通过libvirt管理kvm
    dashboard：kvm虚拟化web管理界面
	其中云硬盘除了cinder还有clusterFS，可以做热迁移
	nova中nova-scheduler做调度器寻找可用的计算节点nova-computer
	cinder依赖于时间同步
                            </ol>
                        </pre>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
    <!--jquery-->
    <script src="../../../../js/index/jquery-3.3.1.min.js"></script>
    <!--jquery.nav-->
    <script src="../../../../product/jqueryui/jquery.nav.js"></script>
    <!--jqueryui-->
    <script src="../../../../product/jqueryui/jquery-ui.min.js"></script>

    <script>
        $( "#nav" ).accordion({
            collapsible: true
        });
        $(function(){
            $('#nav').onePageNav();
        });
    </script>
</html>